{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tflm.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/srinath116/brain-tumor-classification/blob/master/tflm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rij5CuSdBMZ2",
        "colab_type": "code",
        "outputId": "a6194165-5ca7-441c-e2d0-77d599cc9c29",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "from keras import applications\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras import optimizers\n",
        "from keras.models import Sequential, Model \n",
        "from keras.layers import Dropout, Flatten, Dense, GlobalAveragePooling2D\n",
        "from keras import backend as k \n",
        "import keras\n",
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, TensorBoard, EarlyStopping\n",
        "from sklearn.model_selection import KFold\n",
        "img_width, img_height = 256, 256\n",
        "kf = KFold(n_splits=5,random_state=None, shuffle=True)\n",
        "\n",
        "batch_size = 50\n",
        "epochs = 10"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q0tVQrHlBSZZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import applications"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "laHtEDpMBmxd",
        "colab_type": "code",
        "outputId": "4f1c3d87-cf38-468a-d67e-f415ac77ca15",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        }
      },
      "source": [
        "img_width=256\n",
        "img_height=256\n",
        "model = applications.inception_v3.InceptionV3(weights = \"imagenet\", include_top=False, input_shape = (img_width, img_height, 3))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4271: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o7_IbGZwjhOI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ACCURACY_THRESHOLD = 0.80\n",
        "\n",
        "class myCallback(keras.callbacks.Callback):\n",
        "\tdef on_epoch_end(self, epoch, logs={}):\n",
        "\t\tif(logs.get('val_acc') > ACCURACY_THRESHOLD):\n",
        "\t\t\tprint(\"\\nReached %2.2f%% accuracy, so stopping training!!\" %(ACCURACY_THRESHOLD*100))\n",
        "\t\t\tself.model.stop_training = True\n",
        "\n",
        "# Instantiate a callback object\n",
        "callbacks = myCallback()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9h1LDBIUCuye",
        "colab_type": "code",
        "outputId": "7e9dcb6a-a59f-41f4-ed44-2d6fb9d9b33a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from keras import regularizers\n",
        "for layer in model.layers:\n",
        "    layer.trainable = False\n",
        "x=Flatten()(model.get_output_at(-1))\n",
        "x = Dense(1000, activation='relu',input_shape=model.output_shape[1:],kernel_regularizer=regularizers.l2(0.001))(x)\n",
        "\n",
        "predictions = Dense(3, activation=\"softmax\",name='output')(x)\n",
        "\n",
        "# creating the final model \n",
        "\n",
        "model_final = Model(inputs=model.input,output=predictions)\n",
        "adamopt=optimizers.Adam(0.0003)\n",
        "# compile the model \n",
        "\n",
        "model_final.compile(loss=keras.losses.categorical_crossentropy, optimizer=adamopt, metrics=[\"accuracy\"])\n",
        "model_final.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 256, 256, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 127, 127, 32) 864         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 127, 127, 32) 96          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 127, 127, 32) 0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 125, 125, 32) 9216        activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 125, 125, 32) 96          conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 125, 125, 32) 0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 125, 125, 64) 18432       activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 125, 125, 64) 192         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 125, 125, 64) 0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 62, 62, 64)   0           activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 62, 62, 80)   5120        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 62, 62, 80)   240         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 62, 62, 80)   0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 60, 60, 192)  138240      activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 60, 60, 192)  576         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 60, 60, 192)  0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 29, 29, 192)  0           activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 29, 29, 64)   12288       max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 29, 29, 64)   192         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 29, 29, 64)   0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 29, 29, 48)   9216        max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 29, 29, 96)   55296       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 29, 29, 48)   144         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 29, 29, 96)   288         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 29, 29, 48)   0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 29, 29, 96)   0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 29, 29, 192)  0           max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 29, 29, 64)   12288       max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 29, 29, 64)   76800       activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 29, 29, 96)   82944       activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 29, 29, 32)   6144        average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 29, 29, 64)   192         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 29, 29, 64)   192         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 29, 29, 96)   288         conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 29, 29, 32)   96          conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 29, 29, 64)   0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 29, 29, 64)   0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 29, 29, 96)   0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 29, 29, 32)   0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 29, 29, 256)  0           activation_6[0][0]               \n",
            "                                                                 activation_8[0][0]               \n",
            "                                                                 activation_11[0][0]              \n",
            "                                                                 activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 29, 29, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 29, 29, 64)   192         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 29, 29, 64)   0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 29, 29, 48)   12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 29, 29, 96)   55296       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 29, 29, 48)   144         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 29, 29, 96)   288         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 29, 29, 48)   0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 29, 29, 96)   0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_2 (AveragePoo (None, 29, 29, 256)  0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 29, 29, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 29, 29, 64)   76800       activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 29, 29, 96)   82944       activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 29, 29, 64)   16384       average_pooling2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 29, 29, 64)   192         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 29, 29, 64)   192         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 29, 29, 96)   288         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 29, 29, 64)   192         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 29, 29, 64)   0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 29, 29, 64)   0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 29, 29, 96)   0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 29, 29, 64)   0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 29, 29, 288)  0           activation_13[0][0]              \n",
            "                                                                 activation_15[0][0]              \n",
            "                                                                 activation_18[0][0]              \n",
            "                                                                 activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 29, 29, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 29, 29, 64)   192         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 29, 29, 64)   0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 29, 29, 48)   13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 29, 29, 96)   55296       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 29, 29, 48)   144         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 29, 29, 96)   288         conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 29, 29, 48)   0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 29, 29, 96)   0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_3 (AveragePoo (None, 29, 29, 288)  0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 29, 29, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 29, 29, 64)   76800       activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 29, 29, 96)   82944       activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 29, 29, 64)   18432       average_pooling2d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 29, 29, 64)   192         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 29, 29, 64)   192         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 29, 29, 96)   288         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 29, 29, 64)   192         conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 29, 29, 64)   0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 29, 29, 64)   0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 29, 29, 96)   0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 29, 29, 64)   0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 29, 29, 288)  0           activation_20[0][0]              \n",
            "                                                                 activation_22[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "                                                                 activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 29, 29, 64)   18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 29, 29, 64)   192         conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 29, 29, 64)   0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 29, 29, 96)   55296       activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 29, 29, 96)   288         conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 29, 29, 96)   0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 14, 14, 384)  995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 14, 14, 96)   82944       activation_29[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 14, 14, 384)  1152        conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 14, 14, 96)   288         conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 14, 14, 384)  0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 14, 14, 96)   0           batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 14, 14, 288)  0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 14, 14, 768)  0           activation_27[0][0]              \n",
            "                                                                 activation_30[0][0]              \n",
            "                                                                 max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 14, 14, 128)  98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 14, 14, 128)  384         conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 14, 14, 128)  0           batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 14, 14, 128)  114688      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 14, 14, 128)  384         conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 14, 14, 128)  0           batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 14, 14, 128)  98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 14, 14, 128)  114688      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 14, 14, 128)  384         conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 14, 14, 128)  384         conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 14, 14, 128)  0           batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 14, 14, 128)  0           batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 14, 14, 128)  114688      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 14, 14, 128)  114688      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 14, 14, 128)  384         conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, 14, 14, 128)  384         conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 14, 14, 128)  0           batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 14, 14, 128)  0           batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_4 (AveragePoo (None, 14, 14, 768)  0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 14, 14, 192)  147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 14, 14, 192)  172032      activation_33[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 14, 14, 192)  172032      activation_38[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 14, 14, 192)  147456      average_pooling2d_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 14, 14, 192)  576         conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 14, 14, 192)  576         conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, 14, 14, 192)  576         conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, 14, 14, 192)  576         conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 14, 14, 192)  0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 14, 14, 192)  0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 14, 14, 192)  0           batch_normalization_39[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 14, 14, 192)  0           batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, 14, 14, 768)  0           activation_31[0][0]              \n",
            "                                                                 activation_34[0][0]              \n",
            "                                                                 activation_39[0][0]              \n",
            "                                                                 activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 14, 14, 160)  122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_45 (BatchNo (None, 14, 14, 160)  480         conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 14, 14, 160)  0           batch_normalization_45[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 14, 14, 160)  179200      activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_46 (BatchNo (None, 14, 14, 160)  480         conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 14, 14, 160)  0           batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 14, 14, 160)  122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 14, 14, 160)  179200      activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, 14, 14, 160)  480         conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, 14, 14, 160)  480         conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 14, 14, 160)  0           batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 14, 14, 160)  0           batch_normalization_47[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 14, 14, 160)  179200      activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 14, 14, 160)  179200      activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, 14, 14, 160)  480         conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, 14, 14, 160)  480         conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 14, 14, 160)  0           batch_normalization_43[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 14, 14, 160)  0           batch_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_5 (AveragePoo (None, 14, 14, 768)  0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 14, 14, 192)  147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 14, 14, 192)  215040      activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 14, 14, 192)  215040      activation_48[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 14, 14, 192)  147456      average_pooling2d_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, 14, 14, 192)  576         conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, 14, 14, 192)  576         conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, 14, 14, 192)  576         conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_50 (BatchNo (None, 14, 14, 192)  576         conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 14, 14, 192)  0           batch_normalization_41[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 14, 14, 192)  0           batch_normalization_44[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 14, 14, 192)  0           batch_normalization_49[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 14, 14, 192)  0           batch_normalization_50[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, 14, 14, 768)  0           activation_41[0][0]              \n",
            "                                                                 activation_44[0][0]              \n",
            "                                                                 activation_49[0][0]              \n",
            "                                                                 activation_50[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 14, 14, 160)  122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_55 (BatchNo (None, 14, 14, 160)  480         conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 14, 14, 160)  0           batch_normalization_55[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 14, 14, 160)  179200      activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_56 (BatchNo (None, 14, 14, 160)  480         conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 14, 14, 160)  0           batch_normalization_56[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 14, 14, 160)  122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 14, 14, 160)  179200      activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_52 (BatchNo (None, 14, 14, 160)  480         conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_57 (BatchNo (None, 14, 14, 160)  480         conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 14, 14, 160)  0           batch_normalization_52[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 14, 14, 160)  0           batch_normalization_57[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 14, 14, 160)  179200      activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 14, 14, 160)  179200      activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_53 (BatchNo (None, 14, 14, 160)  480         conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_58 (BatchNo (None, 14, 14, 160)  480         conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 14, 14, 160)  0           batch_normalization_53[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 14, 14, 160)  0           batch_normalization_58[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_6 (AveragePoo (None, 14, 14, 768)  0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 14, 14, 192)  147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 14, 14, 192)  215040      activation_53[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 14, 14, 192)  215040      activation_58[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 14, 14, 192)  147456      average_pooling2d_6[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_51 (BatchNo (None, 14, 14, 192)  576         conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_54 (BatchNo (None, 14, 14, 192)  576         conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_59 (BatchNo (None, 14, 14, 192)  576         conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_60 (BatchNo (None, 14, 14, 192)  576         conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 14, 14, 192)  0           batch_normalization_51[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 14, 14, 192)  0           batch_normalization_54[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 14, 14, 192)  0           batch_normalization_59[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 14, 14, 192)  0           batch_normalization_60[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, 14, 14, 768)  0           activation_51[0][0]              \n",
            "                                                                 activation_54[0][0]              \n",
            "                                                                 activation_59[0][0]              \n",
            "                                                                 activation_60[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, 14, 14, 192)  147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_65 (BatchNo (None, 14, 14, 192)  576         conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 14, 14, 192)  0           batch_normalization_65[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, 14, 14, 192)  258048      activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_66 (BatchNo (None, 14, 14, 192)  576         conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 14, 14, 192)  0           batch_normalization_66[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 14, 14, 192)  147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, 14, 14, 192)  258048      activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_62 (BatchNo (None, 14, 14, 192)  576         conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_67 (BatchNo (None, 14, 14, 192)  576         conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 14, 14, 192)  0           batch_normalization_62[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 14, 14, 192)  0           batch_normalization_67[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 14, 14, 192)  258048      activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, 14, 14, 192)  258048      activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_63 (BatchNo (None, 14, 14, 192)  576         conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_68 (BatchNo (None, 14, 14, 192)  576         conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 14, 14, 192)  0           batch_normalization_63[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 14, 14, 192)  0           batch_normalization_68[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_7 (AveragePoo (None, 14, 14, 768)  0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 14, 14, 192)  147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, 14, 14, 192)  258048      activation_63[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, 14, 14, 192)  258048      activation_68[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_70 (Conv2D)              (None, 14, 14, 192)  147456      average_pooling2d_7[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_61 (BatchNo (None, 14, 14, 192)  576         conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_64 (BatchNo (None, 14, 14, 192)  576         conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_69 (BatchNo (None, 14, 14, 192)  576         conv2d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_70 (BatchNo (None, 14, 14, 192)  576         conv2d_70[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 14, 14, 192)  0           batch_normalization_61[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 14, 14, 192)  0           batch_normalization_64[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 14, 14, 192)  0           batch_normalization_69[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_70 (Activation)      (None, 14, 14, 192)  0           batch_normalization_70[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, 14, 14, 768)  0           activation_61[0][0]              \n",
            "                                                                 activation_64[0][0]              \n",
            "                                                                 activation_69[0][0]              \n",
            "                                                                 activation_70[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_73 (Conv2D)              (None, 14, 14, 192)  147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_73 (BatchNo (None, 14, 14, 192)  576         conv2d_73[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_73 (Activation)      (None, 14, 14, 192)  0           batch_normalization_73[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_74 (Conv2D)              (None, 14, 14, 192)  258048      activation_73[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_74 (BatchNo (None, 14, 14, 192)  576         conv2d_74[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_74 (Activation)      (None, 14, 14, 192)  0           batch_normalization_74[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_71 (Conv2D)              (None, 14, 14, 192)  147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_75 (Conv2D)              (None, 14, 14, 192)  258048      activation_74[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_71 (BatchNo (None, 14, 14, 192)  576         conv2d_71[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_75 (BatchNo (None, 14, 14, 192)  576         conv2d_75[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_71 (Activation)      (None, 14, 14, 192)  0           batch_normalization_71[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_75 (Activation)      (None, 14, 14, 192)  0           batch_normalization_75[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_72 (Conv2D)              (None, 6, 6, 320)    552960      activation_71[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_76 (Conv2D)              (None, 6, 6, 192)    331776      activation_75[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_72 (BatchNo (None, 6, 6, 320)    960         conv2d_72[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_76 (BatchNo (None, 6, 6, 192)    576         conv2d_76[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_72 (Activation)      (None, 6, 6, 320)    0           batch_normalization_72[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_76 (Activation)      (None, 6, 6, 192)    0           batch_normalization_76[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2D)  (None, 6, 6, 768)    0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed8 (Concatenate)            (None, 6, 6, 1280)   0           activation_72[0][0]              \n",
            "                                                                 activation_76[0][0]              \n",
            "                                                                 max_pooling2d_4[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_81 (Conv2D)              (None, 6, 6, 448)    573440      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_81 (BatchNo (None, 6, 6, 448)    1344        conv2d_81[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_81 (Activation)      (None, 6, 6, 448)    0           batch_normalization_81[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_78 (Conv2D)              (None, 6, 6, 384)    491520      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_82 (Conv2D)              (None, 6, 6, 384)    1548288     activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_78 (BatchNo (None, 6, 6, 384)    1152        conv2d_78[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_82 (BatchNo (None, 6, 6, 384)    1152        conv2d_82[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_78 (Activation)      (None, 6, 6, 384)    0           batch_normalization_78[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_82 (Activation)      (None, 6, 6, 384)    0           batch_normalization_82[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_79 (Conv2D)              (None, 6, 6, 384)    442368      activation_78[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_80 (Conv2D)              (None, 6, 6, 384)    442368      activation_78[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_83 (Conv2D)              (None, 6, 6, 384)    442368      activation_82[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_84 (Conv2D)              (None, 6, 6, 384)    442368      activation_82[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_8 (AveragePoo (None, 6, 6, 1280)   0           mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_77 (Conv2D)              (None, 6, 6, 320)    409600      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_79 (BatchNo (None, 6, 6, 384)    1152        conv2d_79[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_80 (BatchNo (None, 6, 6, 384)    1152        conv2d_80[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_83 (BatchNo (None, 6, 6, 384)    1152        conv2d_83[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_84 (BatchNo (None, 6, 6, 384)    1152        conv2d_84[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_85 (Conv2D)              (None, 6, 6, 192)    245760      average_pooling2d_8[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_77 (BatchNo (None, 6, 6, 320)    960         conv2d_77[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_79 (Activation)      (None, 6, 6, 384)    0           batch_normalization_79[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_80 (Activation)      (None, 6, 6, 384)    0           batch_normalization_80[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_83 (Activation)      (None, 6, 6, 384)    0           batch_normalization_83[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_84 (Activation)      (None, 6, 6, 384)    0           batch_normalization_84[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_85 (BatchNo (None, 6, 6, 192)    576         conv2d_85[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_77 (Activation)      (None, 6, 6, 320)    0           batch_normalization_77[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_0 (Concatenate)          (None, 6, 6, 768)    0           activation_79[0][0]              \n",
            "                                                                 activation_80[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 6, 6, 768)    0           activation_83[0][0]              \n",
            "                                                                 activation_84[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_85 (Activation)      (None, 6, 6, 192)    0           batch_normalization_85[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9 (Concatenate)            (None, 6, 6, 2048)   0           activation_77[0][0]              \n",
            "                                                                 mixed9_0[0][0]                   \n",
            "                                                                 concatenate_1[0][0]              \n",
            "                                                                 activation_85[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_90 (Conv2D)              (None, 6, 6, 448)    917504      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_90 (BatchNo (None, 6, 6, 448)    1344        conv2d_90[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_90 (Activation)      (None, 6, 6, 448)    0           batch_normalization_90[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_87 (Conv2D)              (None, 6, 6, 384)    786432      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_91 (Conv2D)              (None, 6, 6, 384)    1548288     activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_87 (BatchNo (None, 6, 6, 384)    1152        conv2d_87[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_91 (BatchNo (None, 6, 6, 384)    1152        conv2d_91[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_87 (Activation)      (None, 6, 6, 384)    0           batch_normalization_87[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_91 (Activation)      (None, 6, 6, 384)    0           batch_normalization_91[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_88 (Conv2D)              (None, 6, 6, 384)    442368      activation_87[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_89 (Conv2D)              (None, 6, 6, 384)    442368      activation_87[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_92 (Conv2D)              (None, 6, 6, 384)    442368      activation_91[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_93 (Conv2D)              (None, 6, 6, 384)    442368      activation_91[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_9 (AveragePoo (None, 6, 6, 2048)   0           mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_86 (Conv2D)              (None, 6, 6, 320)    655360      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_88 (BatchNo (None, 6, 6, 384)    1152        conv2d_88[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_89 (BatchNo (None, 6, 6, 384)    1152        conv2d_89[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_92 (BatchNo (None, 6, 6, 384)    1152        conv2d_92[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_93 (BatchNo (None, 6, 6, 384)    1152        conv2d_93[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_94 (Conv2D)              (None, 6, 6, 192)    393216      average_pooling2d_9[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_86 (BatchNo (None, 6, 6, 320)    960         conv2d_86[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_88 (Activation)      (None, 6, 6, 384)    0           batch_normalization_88[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_89 (Activation)      (None, 6, 6, 384)    0           batch_normalization_89[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_92 (Activation)      (None, 6, 6, 384)    0           batch_normalization_92[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_93 (Activation)      (None, 6, 6, 384)    0           batch_normalization_93[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_94 (BatchNo (None, 6, 6, 192)    576         conv2d_94[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_86 (Activation)      (None, 6, 6, 320)    0           batch_normalization_86[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_1 (Concatenate)          (None, 6, 6, 768)    0           activation_88[0][0]              \n",
            "                                                                 activation_89[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 6, 6, 768)    0           activation_92[0][0]              \n",
            "                                                                 activation_93[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_94 (Activation)      (None, 6, 6, 192)    0           batch_normalization_94[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed10 (Concatenate)           (None, 6, 6, 2048)   0           activation_86[0][0]              \n",
            "                                                                 mixed9_1[0][0]                   \n",
            "                                                                 concatenate_2[0][0]              \n",
            "                                                                 activation_94[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 73728)        0           mixed10[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 1000)         73729000    flatten_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "output (Dense)                  (None, 3)            3003        dense_1[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 95,534,787\n",
            "Trainable params: 73,732,003\n",
            "Non-trainable params: 21,802,784\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"ou...)`\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-nKJ02goRaa3",
        "colab_type": "code",
        "outputId": "e067ba97-d275-466a-d904-73eea6b0ecb6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TLR0q-jRRUaA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os \n",
        "from zipfile import ZipFile\n",
        "base_path=\"/content/drive/My Drive/tuber_data.zip\";\n",
        "\n",
        "with ZipFile(base_path) as z:\n",
        "    z.extractall()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yba7zy8kTcPV",
        "colab_type": "code",
        "outputId": "06679ea1-93d6-40a9-cae6-2a135a2809a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "import numpy as np\n",
        "# example of converting an image with the Keras API\n",
        "from keras.preprocessing.image import load_img\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from keras.preprocessing.image import array_to_img\n",
        "# load the image\n",
        "\n",
        "# convert to numpy array\n",
        "x= np.zeros((3061, 256, 256, 3))\n",
        "y= np.zeros((3061, 1))\n",
        "final_index = 0\n",
        "for i in range(1,4):\n",
        "  print(i)\n",
        "  for index, image in enumerate(os.listdir('./data_'+str(i))):\n",
        "        img = load_img('./data_'+str(i)+\"/\"+image)\n",
        "        temp=img_to_array(img)/255\n",
        "        if temp.shape[0] == 256:\n",
        "          x[index] = temp\n",
        "          y[index] = i\n",
        "          # print(temp.shape)\n",
        "  final_index += index\n",
        "print(final_index)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n",
            "2\n",
            "3\n",
            "3061\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7l-AQ6bQTiq5",
        "colab_type": "code",
        "outputId": "dab0a014-35e2-459d-9add-170062e922cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "from sklearn.preprocessing import OneHotEncoder \n",
        "  \n",
        "# creating one hot encoder object with categorical feature 0 \n",
        "# indicating the first column \n",
        "onehotencoder = OneHotEncoder(categorical_features = [0]) \n",
        "y = onehotencoder.fit_transform(y).toarray() \n",
        "print(y.shape,x.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3061, 3) (3061, 256, 256, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
            "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
            "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
            "  warnings.warn(msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:451: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n",
            "  \"use the ColumnTransformer instead.\", DeprecationWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VjBP8DAb5vl0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=None,shuffle=True)\n",
        "\n",
        "del x,y\n",
        "# model_final.fit( x_train, y_train, batch_size=50,epochs=10,validation_data=(x_test,y_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qRW0V4wnTpGh",
        "colab_type": "code",
        "outputId": "f0b608cb-d2c8-403b-cd42-a66e82855c16",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "kf.get_n_splits(x_train)\n",
        "\n",
        "print(kf)     \n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "KFold(n_splits=5, random_state=None, shuffle=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Kncwj9s96o9W",
        "outputId": "4ea22c77-ba12-4e49-fbf2-6883f1f9bdff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "i=0;\n",
        "for train_index, test_index in kf.split(x_train):\n",
        "# for i in range(5):\n",
        "  # x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=42)\n",
        " \n",
        "  print(i);\n",
        "  history = model_final.fit( x_train[train_index], y_train[train_index], batch_size=50, epochs=10,validation_data=(x_train[test_index],y_train[test_index]),callbacks=[callbacks] )\n",
        "  # history=model_final.fit( x_train, y_train, batch_size=50, epochs=10,validation_data=(x_test,y_test) )\n",
        "  i=i+1;"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Train on 1836 samples, validate on 459 samples\n",
            "Epoch 1/10\n",
            "1836/1836 [==============================] - 16s 9ms/step - loss: 3.1864 - acc: 0.8818 - val_loss: 10.7389 - val_acc: 0.4292\n",
            "Epoch 2/10\n",
            "1836/1836 [==============================] - 7s 4ms/step - loss: 2.5130 - acc: 0.9395 - val_loss: 11.0901 - val_acc: 0.3878\n",
            "Epoch 3/10\n",
            "1836/1836 [==============================] - 7s 4ms/step - loss: 3.1297 - acc: 0.8965 - val_loss: 11.0265 - val_acc: 0.4031\n",
            "Epoch 4/10\n",
            "1836/1836 [==============================] - 7s 4ms/step - loss: 4.1046 - acc: 0.8322 - val_loss: 10.6117 - val_acc: 0.4248\n",
            "Epoch 5/10\n",
            "1836/1836 [==============================] - 7s 4ms/step - loss: 2.8912 - acc: 0.9009 - val_loss: 12.9621 - val_acc: 0.2767\n",
            "Epoch 6/10\n",
            "1836/1836 [==============================] - 7s 4ms/step - loss: 3.8563 - acc: 0.8382 - val_loss: 12.8466 - val_acc: 0.2767\n",
            "Epoch 7/10\n",
            "1836/1836 [==============================] - 7s 4ms/step - loss: 3.7414 - acc: 0.8382 - val_loss: 12.7368 - val_acc: 0.2767\n",
            "Epoch 8/10\n",
            "1836/1836 [==============================] - 7s 4ms/step - loss: 3.6588 - acc: 0.8279 - val_loss: 6.0449 - val_acc: 0.6754\n",
            "Epoch 9/10\n",
            "1836/1836 [==============================] - 7s 4ms/step - loss: 3.2422 - acc: 0.8568 - val_loss: 10.9199 - val_acc: 0.3660\n",
            "Epoch 10/10\n",
            "1836/1836 [==============================] - 7s 4ms/step - loss: 1.6833 - acc: 0.9564 - val_loss: 12.3242 - val_acc: 0.2919\n",
            "1\n",
            "Train on 1836 samples, validate on 459 samples\n",
            "Epoch 1/10\n",
            "1836/1836 [==============================] - 7s 4ms/step - loss: 1.7199 - acc: 0.9521 - val_loss: 9.8198 - val_acc: 0.4444\n",
            "Epoch 2/10\n",
            "1836/1836 [==============================] - 7s 4ms/step - loss: 1.6587 - acc: 0.9532 - val_loss: 9.8315 - val_acc: 0.4423\n",
            "Epoch 3/10\n",
            "1836/1836 [==============================] - 7s 4ms/step - loss: 1.3577 - acc: 0.9700 - val_loss: 10.1783 - val_acc: 0.4161\n",
            "Epoch 4/10\n",
            "1836/1836 [==============================] - 7s 4ms/step - loss: 1.4356 - acc: 0.9635 - val_loss: 9.6659 - val_acc: 0.4532\n",
            "Epoch 5/10\n",
            "1836/1836 [==============================] - 7s 4ms/step - loss: 1.3631 - acc: 0.9657 - val_loss: 9.4126 - val_acc: 0.4641\n",
            "Epoch 6/10\n",
            "1836/1836 [==============================] - 7s 4ms/step - loss: 1.0888 - acc: 0.9804 - val_loss: 9.3643 - val_acc: 0.4575\n",
            "Epoch 7/10\n",
            "1836/1836 [==============================] - 7s 4ms/step - loss: 1.2205 - acc: 0.9684 - val_loss: 9.7324 - val_acc: 0.4401\n",
            "Epoch 8/10\n",
            "1836/1836 [==============================] - 7s 4ms/step - loss: 1.1000 - acc: 0.9744 - val_loss: 9.3343 - val_acc: 0.4619\n",
            "Epoch 9/10\n",
            "1836/1836 [==============================] - 7s 4ms/step - loss: 2.8046 - acc: 0.8704 - val_loss: 5.0089 - val_acc: 0.4336\n",
            "Epoch 10/10\n",
            "1836/1836 [==============================] - 7s 4ms/step - loss: 1.0341 - acc: 0.9782 - val_loss: 9.0659 - val_acc: 0.3791\n",
            "2\n",
            "Train on 1836 samples, validate on 459 samples\n",
            "Epoch 1/10\n",
            "1836/1836 [==============================] - 7s 4ms/step - loss: 1.2027 - acc: 0.9641 - val_loss: 4.1563 - val_acc: 0.3682\n",
            "Epoch 2/10\n",
            "1836/1836 [==============================] - 7s 4ms/step - loss: 1.0051 - acc: 0.9804 - val_loss: 1.1121 - val_acc: 0.9630\n",
            "\n",
            "Reached 80.00% accuracy, so stopping training!!\n",
            "3\n",
            "Train on 1836 samples, validate on 459 samples\n",
            "Epoch 1/10\n",
            "1836/1836 [==============================] - 7s 4ms/step - loss: 1.1614 - acc: 0.9657 - val_loss: 9.7443 - val_acc: 0.4336\n",
            "Epoch 2/10\n",
            "1836/1836 [==============================] - 7s 4ms/step - loss: 0.9035 - acc: 0.9837 - val_loss: 11.7886 - val_acc: 0.3028\n",
            "Epoch 3/10\n",
            "1836/1836 [==============================] - 7s 4ms/step - loss: 0.9765 - acc: 0.9766 - val_loss: 10.8823 - val_acc: 0.3551\n",
            "Epoch 4/10\n",
            "1836/1836 [==============================] - 7s 4ms/step - loss: 1.0805 - acc: 0.9706 - val_loss: 9.7310 - val_acc: 0.4357\n",
            "Epoch 5/10\n",
            "1836/1836 [==============================] - 7s 4ms/step - loss: 1.0046 - acc: 0.9760 - val_loss: 9.8391 - val_acc: 0.4183\n",
            "Epoch 6/10\n",
            "1836/1836 [==============================] - 7s 4ms/step - loss: 0.7927 - acc: 0.9891 - val_loss: 9.5547 - val_acc: 0.4444\n",
            "Epoch 7/10\n",
            "1836/1836 [==============================] - 7s 4ms/step - loss: 1.1728 - acc: 0.9619 - val_loss: 9.4423 - val_acc: 0.4444\n",
            "Epoch 8/10\n",
            "1836/1836 [==============================] - 7s 4ms/step - loss: 0.7876 - acc: 0.9864 - val_loss: 9.9830 - val_acc: 0.4118\n",
            "Epoch 9/10\n",
            "1836/1836 [==============================] - 7s 4ms/step - loss: 0.9179 - acc: 0.9777 - val_loss: 10.7314 - val_acc: 0.3638\n",
            "Epoch 10/10\n",
            "1836/1836 [==============================] - 7s 4ms/step - loss: 0.7101 - acc: 0.9897 - val_loss: 6.5307 - val_acc: 0.4379\n",
            "4\n",
            "Train on 1836 samples, validate on 459 samples\n",
            "Epoch 1/10\n",
            "1836/1836 [==============================] - 7s 4ms/step - loss: 0.8747 - acc: 0.9755 - val_loss: 7.7409 - val_acc: 0.4423\n",
            "Epoch 2/10\n",
            "1836/1836 [==============================] - 7s 4ms/step - loss: 0.7994 - acc: 0.9837 - val_loss: 4.1567 - val_acc: 0.4357\n",
            "Epoch 3/10\n",
            "1836/1836 [==============================] - 7s 4ms/step - loss: 0.8809 - acc: 0.9771 - val_loss: 7.5948 - val_acc: 0.4379\n",
            "Epoch 4/10\n",
            "1836/1836 [==============================] - 7s 4ms/step - loss: 0.6352 - acc: 0.9918 - val_loss: 6.0202 - val_acc: 0.4379\n",
            "Epoch 5/10\n",
            "1836/1836 [==============================] - 7s 4ms/step - loss: 0.7095 - acc: 0.9847 - val_loss: 2.1633 - val_acc: 0.4401\n",
            "Epoch 6/10\n",
            "1836/1836 [==============================] - 7s 4ms/step - loss: 0.6775 - acc: 0.9875 - val_loss: 0.7252 - val_acc: 0.9804\n",
            "\n",
            "Reached 80.00% accuracy, so stopping training!!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fTN9g0nKsn6a",
        "colab_type": "code",
        "outputId": "626cb584-af25-4390-8919-7369a63f55ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "scores= model_final.evaluate(x=x_test,y=y_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "766/766 [==============================] - 3s 4ms/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I5hMIhBUfHZ4",
        "colab_type": "code",
        "outputId": "aaff4f8e-823f-47ce-d119-ff1cbda1abc7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(\"%s: %.2f%%\" % (model_final.metrics_names[1], scores[1]*100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "acc: 96.74%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1urLiakofRxh",
        "colab_type": "code",
        "outputId": "7cfadb38-a257-4045-c1b7-df6394ad91b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(model_final.metrics_names)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['loss', 'acc']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VKY7JWwWgdHh",
        "colab_type": "code",
        "outputId": "75646988-17d3-492e-d9da-8503a35962d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        }
      },
      "source": [
        "from matplotlib import pyplot\n",
        "# plot loss during training\n",
        "pyplot.subplot(211)\n",
        "pyplot.title('Loss')\n",
        "pyplot.plot(history.history['loss'], label='train')\n",
        "pyplot.plot(history.history['val_loss'], label='test')\n",
        "pyplot.legend()\n",
        "# plot accuracy during training\n",
        "pyplot.subplot(212)\n",
        "pyplot.title('Accuracy')\n",
        "pyplot.plot(history.history['acc'], label='train')\n",
        "pyplot.plot(history.history['val_acc'], label='test')\n",
        "pyplot.legend()\n",
        "pyplot.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WP_FPKRwgvi5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "yhat_classes = model_final.predict(x_test, verbose=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xh8X6ykEgxdz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_predclasses=np.argmax(yhat_classes,axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DOkI-WaDhNHH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_actual=np.argmax(y_test,axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xVNOM9DLPl6K",
        "colab_type": "code",
        "outputId": "465a62d2-1067-4fcb-c6fa-553cd6a1105d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "target_names = ['class 0', 'class 1', 'class 2']\n",
        "print(classification_report(y_predclasses, y_actual, target_names=target_names))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "     class 0       1.00      0.97      0.99       414\n",
            "     class 1       0.84      0.97      0.90       112\n",
            "     class 2       0.98      0.95      0.97       240\n",
            "\n",
            "    accuracy                           0.97       766\n",
            "   macro avg       0.94      0.97      0.95       766\n",
            "weighted avg       0.97      0.97      0.97       766\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s77cpGKZGbaq",
        "colab_type": "code",
        "outputId": "55b02416-4463-47cf-eee3-60f7e16db705",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/device:GPU:0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D3LW2nIMGclc",
        "colab_type": "code",
        "outputId": "2df595dd-bbeb-4475-d47e-4af016098281",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!cat /proc/cpuinfo\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "processor\t: 0\n",
            "vendor_id\t: GenuineIntel\n",
            "cpu family\t: 6\n",
            "model\t\t: 63\n",
            "model name\t: Intel(R) Xeon(R) CPU @ 2.30GHz\n",
            "stepping\t: 0\n",
            "microcode\t: 0x1\n",
            "cpu MHz\t\t: 2300.000\n",
            "cache size\t: 46080 KB\n",
            "physical id\t: 0\n",
            "siblings\t: 4\n",
            "core id\t\t: 0\n",
            "cpu cores\t: 2\n",
            "apicid\t\t: 0\n",
            "initial apicid\t: 0\n",
            "fpu\t\t: yes\n",
            "fpu_exception\t: yes\n",
            "cpuid level\t: 13\n",
            "wp\t\t: yes\n",
            "flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid xsaveopt arat md_clear arch_capabilities\n",
            "bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs\n",
            "bogomips\t: 4600.00\n",
            "clflush size\t: 64\n",
            "cache_alignment\t: 64\n",
            "address sizes\t: 46 bits physical, 48 bits virtual\n",
            "power management:\n",
            "\n",
            "processor\t: 1\n",
            "vendor_id\t: GenuineIntel\n",
            "cpu family\t: 6\n",
            "model\t\t: 63\n",
            "model name\t: Intel(R) Xeon(R) CPU @ 2.30GHz\n",
            "stepping\t: 0\n",
            "microcode\t: 0x1\n",
            "cpu MHz\t\t: 2300.000\n",
            "cache size\t: 46080 KB\n",
            "physical id\t: 0\n",
            "siblings\t: 4\n",
            "core id\t\t: 1\n",
            "cpu cores\t: 2\n",
            "apicid\t\t: 2\n",
            "initial apicid\t: 2\n",
            "fpu\t\t: yes\n",
            "fpu_exception\t: yes\n",
            "cpuid level\t: 13\n",
            "wp\t\t: yes\n",
            "flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid xsaveopt arat md_clear arch_capabilities\n",
            "bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs\n",
            "bogomips\t: 4600.00\n",
            "clflush size\t: 64\n",
            "cache_alignment\t: 64\n",
            "address sizes\t: 46 bits physical, 48 bits virtual\n",
            "power management:\n",
            "\n",
            "processor\t: 2\n",
            "vendor_id\t: GenuineIntel\n",
            "cpu family\t: 6\n",
            "model\t\t: 63\n",
            "model name\t: Intel(R) Xeon(R) CPU @ 2.30GHz\n",
            "stepping\t: 0\n",
            "microcode\t: 0x1\n",
            "cpu MHz\t\t: 2300.000\n",
            "cache size\t: 46080 KB\n",
            "physical id\t: 0\n",
            "siblings\t: 4\n",
            "core id\t\t: 0\n",
            "cpu cores\t: 2\n",
            "apicid\t\t: 1\n",
            "initial apicid\t: 1\n",
            "fpu\t\t: yes\n",
            "fpu_exception\t: yes\n",
            "cpuid level\t: 13\n",
            "wp\t\t: yes\n",
            "flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid xsaveopt arat md_clear arch_capabilities\n",
            "bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs\n",
            "bogomips\t: 4600.00\n",
            "clflush size\t: 64\n",
            "cache_alignment\t: 64\n",
            "address sizes\t: 46 bits physical, 48 bits virtual\n",
            "power management:\n",
            "\n",
            "processor\t: 3\n",
            "vendor_id\t: GenuineIntel\n",
            "cpu family\t: 6\n",
            "model\t\t: 63\n",
            "model name\t: Intel(R) Xeon(R) CPU @ 2.30GHz\n",
            "stepping\t: 0\n",
            "microcode\t: 0x1\n",
            "cpu MHz\t\t: 2300.000\n",
            "cache size\t: 46080 KB\n",
            "physical id\t: 0\n",
            "siblings\t: 4\n",
            "core id\t\t: 1\n",
            "cpu cores\t: 2\n",
            "apicid\t\t: 3\n",
            "initial apicid\t: 3\n",
            "fpu\t\t: yes\n",
            "fpu_exception\t: yes\n",
            "cpuid level\t: 13\n",
            "wp\t\t: yes\n",
            "flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid xsaveopt arat md_clear arch_capabilities\n",
            "bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs\n",
            "bogomips\t: 4600.00\n",
            "clflush size\t: 64\n",
            "cache_alignment\t: 64\n",
            "address sizes\t: 46 bits physical, 48 bits virtual\n",
            "power management:\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SthkzgS6HrZm",
        "colab_type": "code",
        "outputId": "b28c4a27-bc3d-4464-c0a1-197c2a154f5d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!cat /proc/gpuinfo"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cat: /proc/gpuinfo: No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}